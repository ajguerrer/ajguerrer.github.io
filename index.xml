<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Notebook</title>
    <link>https://ajguerrer.github.io/</link>
    <description>Recent content on Notebook</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://ajguerrer.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>The Bigger Picture</title>
      <link>https://ajguerrer.github.io/unit-testing/bigger_picture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ajguerrer.github.io/unit-testing/bigger_picture/</guid>
      <description>What Makes a Good or Bad Test?  Unit testing enables sustainable growth in software projects by acting as a form of insurance against regressions. A good test has a lower maintenance cost than the cost of fixing the bugs it prevents. Code is a liability, not an asset, and tests are code too. Tests that don&amp;rsquo;t verify business value, raise false alarms, run slow, and are difficult to maintain, do more harm than good.</description>
    </item>
    
    <item>
      <title>Making your Tests Work for You</title>
      <link>https://ajguerrer.github.io/unit-testing/making_tests_work/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ajguerrer.github.io/unit-testing/making_tests_work/</guid>
      <description>Four Pillars of a Good Test  Protection against regressions - Ability to indicate the presence of regressions. Resistance to refactoring - Degree to which a test can sustain refactoring without producing a false positive. Fast feedback - Measure of how quickly the test executes. Maintainability - Ability to read and run the test.    Error Types Functionality is Correct Functionality is Broken   Test Passes True negative False negative (indicates poor protection against regressions)   Test Fails False positive (indicates poor resistance to refactoring) True positive   $$Test\ accuracy = {Signal\ (True\ positives) \over Noise\ (False\ positives)}$$</description>
    </item>
    
    <item>
      <title>Integration Testing</title>
      <link>https://ajguerrer.github.io/unit-testing/integration_testing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ajguerrer.github.io/unit-testing/integration_testing/</guid>
      <description>Role of Integration Tests Integration tests verify:
 Interactions with external dependencies. Edge cases unsuitable for a unit test.  Each integration test should choose a happy path that exercises as many shared external dependencies as possible while staying within a single use case. If a single integration test doesn&amp;rsquo;t cover all shared external dependencies, write more until all external dependencies are covered.
To keep maintenance costs low, check as many edge cases as possible with unit tests before resorting to an integration test.</description>
    </item>
    
    <item>
      <title>Unit Testing Anti-Patterns</title>
      <link>https://ajguerrer.github.io/unit-testing/antipatterns/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ajguerrer.github.io/unit-testing/antipatterns/</guid>
      <description>Don&amp;rsquo;t test private methods directly Only test observable behavior. Coupling a test to implementation details will reduce the tests resistance to refactoring.
class Order { public: std::string GenerateDescription(); private: float GetPrice(); Customer customer_; std::vector&amp;lt;Product&amp;gt; products_; }; std::string Order::GenerateDescription() { return absl::StrCat(&amp;#34;Customer name: &amp;#34;, customer_.name, &amp;#34;, total number of products: &amp;#34;, products_.size(), &amp;#34;, total price: &amp;#34;, GetPrice()); } float Order::GetPrice() { float basePrice = std::accumulate(products_.begin(), products_.end(), 0.0, sum_base_prices); float discount = customer_.</description>
    </item>
    
    <item>
      <title>General Notes</title>
      <link>https://ajguerrer.github.io/google-testing-blog/general/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ajguerrer.github.io/google-testing-blog/general/</guid>
      <description>Test Reliability  Smaller tests run faster, are less flakey, and isolate failures. As a general rule of thumb, favor a composition of 70% small, 20% medium, and 10% large tests.1 Test binary size and memory usage, including third-party testing tools, have a strong correlation on whether a test is flaky.2 Beware of using UI testing to verify underlying functionality. In these cases, it is cheaper and more reliable to have smaller tests that break closer to the source of the problem.</description>
    </item>
    
    <item>
      <title>Guide to Writing Testable Code</title>
      <link>https://ajguerrer.github.io/google-testing-blog/testable_code/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ajguerrer.github.io/google-testing-blog/testable_code/</guid>
      <description>Miško Hevery  You may find Miško&amp;rsquo;s original guide here.
Dependency Injection A testable class is one that can be constructed in isolation or with test double collaborators. Once constructed, they have all the dependencies they need. This is known as Dependency Injection.
Dependencies do not need to be concrete classes. Abstract classes allow testers to leverage inheritance for creating test double collaborators. This is the primary tool in a testers toolkit and the primary benefit Dependency Injection brings.</description>
    </item>
    
    <item>
      <title>James Whittaker</title>
      <link>https://ajguerrer.github.io/google-testing-blog/whittaker/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ajguerrer.github.io/google-testing-blog/whittaker/</guid>
      <description>The Seven Plagues of Software Testing  Aimlessness - Do not test for the sake of testing. Every test should have a goal. Document what works and analyze what doesn&amp;rsquo;t. Then, share with your colleagues.1 Repetitiveness - Running the same test suite over again without finding new bugs does not mean that there are no bugs. Variation is healthy.2 Amnesia - Chances are the problem your are trying to solve has been solved before.</description>
    </item>
    
    <item>
      <title>Testing on the Toilet</title>
      <link>https://ajguerrer.github.io/google-testing-blog/tott/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ajguerrer.github.io/google-testing-blog/tott/</guid>
      <description>This page contains potable bits of testing best-practices that will keep you riveted to your seat.
Tests Too DRY? Make Them DAMP! December 03, 2019 - original post
Though the DRY (&amp;ldquo;Don&amp;rsquo;t Repeat Yourself&amp;rdquo;) principle is great for production code, tests don&amp;rsquo;t test themselves.
class ForumTest : public ::testing::Test { protected: void SetUp() override { for (auto user : users_) { forum_.Register(user); } } Forum forum_; std::vector&amp;lt;User&amp;gt; users_ = {User(&amp;#34;Alice&amp;#34;), User(&amp;#34;Bob&amp;#34;)}; } TEST_F(ForumTest, CanRegisterMultipleUsers) { for (auto user : users_) { EXPECT_TRUE(forum_.</description>
    </item>
    
  </channel>
</rss>